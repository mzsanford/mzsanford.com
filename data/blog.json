{
    "categories": [], 
    "description": "Code, Movies, Whatever strikes my fancy.", 
    "link": "http://mzsanford.wordpress.com", 
    "posts": [
        {
            "categories": [
                "Languages", 
                "Programming"
            ], 
            "comments": [
                {
                    "author": "5ubliminal", 
                    "author_email": "wm@5ubliminal.com", 
                    "author_ip": "86.121.14.130", 
                    "author_url": "http://blog.5ubliminal.com/", 
                    "content": "Or use this method of <a href=\"http://blog.5ubliminal.com/78\" rel=\"nofollow\">language detection based on text</a> courtesy of Google.", 
                    "post_date": "2009/04/09 19:15:56Z"
                }
            ], 
            "content": "There have been a few questions on the Twitter API development list asking about how search.twitter.com is able to detect the language of a tweet. The methods used are nothing new to the field of natural language processing (NLP), but most developers haven't studied much NLP. I'll cover the industry standard method we're using, as well as the shortcomings.\n<!--more-->\nI'm a language geek but not a linguist or NLP scientist so I started with a knowledge of programming but not of the existing techniques for language detection. I was able to recognize spoken and written languages I didn't speak and that sparked my interest in what I was gleaning that information from. I'm no protege so there must be some simple mental process. I thought language-specific search would be nice so I read up and started on the code.\n<h2>Most Common Words</h2>\nMy first thought was that you can determine a language by using some of the most common words. I spent a lazy Saturday afternoon thinking about it and came up with an idea. While 'die' is a word in English, it's a very common article in German (feminine 'the'). I started to think about how I could leverage that knowledge to detect languages but ran into a wall. You see, I speak German so it wasn't a good explanation for my ability to pick up the difference between spoken Chinese and Korean. Those two bring up a good point, the way I determine those in writing (characters) differs from how I do in speech (tones). In languages, the most common words tend to be the shortest and with only a limited number of syllables it seemed like my common-words method was doomed to failure.\n\nIt seemed clear my first idea wasn't going to work but it seemed close to a statistical method for identifying a language. That phrase 'statistical method' made me think of conference papers so I started searching those. That reading not only brought me up to speed on the current state of language detection, but increased my general language interest.\n<h2>Character Distribution</h2>\nI was pleasantly surprised to find out I wasn't totally off base in looking at distribution of the data. It's the basis of statistical analysis so how could I really be that far off, but being new to all of this I feared I had made the most rookie of mistakes. It turns out that if you chop words up into groups of letters and store the distribution for each language they are different enough to let you determine a language with pretty good accuracy.\n\nThis method is very successful but in requires that you have a large set of training data for each language in order to get an accurate distribution. There are some academic collections you can use, but not for a commercial product. My background in is in web crawlers, so crawling a series of sites for each language seemed reasonable. The problem was, without language detection I wouldn't know what language it was. A bit of a catch-22.\n\nEnter Wikipedia. There data is divided by language, freely available, large, and created on a variety of subjects by a variety of authors. In my brief NLP and language reading I had already learned that the subject, author and audience of a work will have a large influence on the types of words used. For example, if you did your English training on legal contracts you would think we say use much more Latin that we really do.\n\nThe code for doing this character distribution work can be found in <a title=\"Nutch\" href=\"http://lucene.apache.org/nutch/\" target=\"_blank\">Nutch</a>. That code was hard to find when searching for language detection. Being a crawler developer I remembered seeing it and verified it works based on character distribution. My crawlers and my language hobby were coming together at last. I did some crawling for additional languages from Wikipedia and then realized that ideographic language fail using this method since they don't use as restrictive of an alphabet.\n<h2>Ideographic Languages</h2>\nWhile the character distribution method handles languages using the Latin alphabet really well it does break down on some other alphabets. It works surprisingly well on languages using the Arabic alphabet (Arabic, Farsi, etc), as well as Cyrillic, Hebrew and a slew of others. I am guessing any semi-phonetic language is going to match that pattern. Where it has problems is Kanji, since a word is not made up of a combination of characters from a small set.\n\nI don't speak Chinese or Japanese but I used them as a good example of two ideographic languages that the character distribution method fails to differentiate. What's interesting between these two is that Japanese actually uses several different character sets for text. You can see in the Unicode table there are Kanji, Hiragana and Katakana \u2026 which got me thinking: What if you used the statistical distribution of character sets?\n\nAs it turns out this gives reasonably good results. Good enough that they are worth keeping. I removed all ideographic training data from the character distribution check and made the code try a second method where it checks the character <strong>set</strong> distribution. A bit of manual evaluation and some checks for minimum confidence later and it seems like we are sorting Chinese from Japanese correctly often enough to make me, a non-speaker, happy.\n<h2>Conclusions</h2>\nI'm not a linguist. I'm not a computational linguist. I'm a programmer who is facinated with language. I learned the basics of language detection and extended it a little to cover ideographic scripts. I've had some success and I hope this helps you have a little too. Our training data still needs some work, but I think over all I've found a solution that is pretty damn good for the cost \u2026 which was my time and a little CPU.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "5", 
            "link": "http://mzsanford.wordpress.com/2009/01/26/language-detection-geekery/", 
            "name": "language-detection-geekery", 
            "post_date": "2009/01/27 00:40:21Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Language Detection Geekery"
        }, 
        {
            "categories": [
                "Languages", 
                "Programming"
            ], 
            "comments": [], 
            "content": "When English speaking developers first encounter languages like Hebrew or Arabic where things are written from right to left they react in one of two ways. Either they see this as insurmountable to support in their application or they feel the opposite and assume that since they have UTF-8 everything will just work. While most modern programming languages support UTF-8 encoding that does not mean that everything does it correctly, and often the right-to-left layout is an overlooked part of UTF-8 support. This post hopes to clarify a little bit about right-to-left processing and Arabic in particular since I speak some of that and it inspired this post.\n<!--more-->\nFor the more detail oriented please note that I've skipped any discussion of endian-ness.\n\n<h2>Which Way Do The <em>Bytes</em> Go?</h2>\nThis is a common source of confusion with right to left languages, even for advanced developers. When English developers think of text they think of bytes streaming from left to right, top to bottom, the same way they read. While that's the way we visualize the data it is, in fact, just a string of bytes without any direction. It's best to break with any confusing directionality and think of the bytes as running in a single top-to-bottom line. Here's some sample english text to belabor the point:\n<pre>abcd  0x61 0x62 0x63 0x64\n\nbecomes:\n\na  0x61\nb  0x62\nc  0x63\nd  0x64</pre>\nWith that little visual exercise out of the way I can move on to right-to-left languages. If you look at the second part of the above it is the same order was the bytes used for right-to-left languages. <strong>The first character a native speaker would write is the first character in the data stream</strong>, the second comes next, and so on. This is nothing revolutionary but I can't count the number of times I have heard skilled developers say things like \"but in Arabic the string is backwards\". It's very easy to fall into the trap, don't be fooled. The string isn't stored in reverse order, it is <em>displayed</em> in reverse order.\n<h2>Who Makes Right-to-left Flow from right to left?</h2>\nAs stated above the bytes for a right-to-left string are stored in the same logical order but are displayed in reverse. That sentence <em>almost</em> makes the assumption that UTF-8 \"just handles\" right-to-left correct. The main problem is that it's all up to the display program to do things correctly. If your application is using a web browser or OS standard text control you're probably using the OS text layout engine. These modern layout engines are probably going to work out fine, I know they do in all of the OS's I've used recently. Where things get more interesting is in graphics processing libraries. If you are writing (or using) a graphics processing library that focuses on primitive drawing (line, shapes, etc) it's very likely the text layout engine was an after thought. It's also pretty likely it was added by an English speaking developer with no thought toward non-Latin scripts (right-to-left as well as ideographic systems like Chinese).\n\nThat's all well and good but it doesn't explain how layout engines <em>should</em> be handling right-to-left layout. I've never designed a text layout engine \u2026 it's hard and the OS native ones do a great job. I'm not writing this to explain how to write a layout engine. Firstly it's a complicated subject of which I only know what I need, and secondly I would caution anyone against writing such a thing again<strong> </strong>. What I want to cover is the basics of how the bytes in the same order as Latin scripts end up the other direction. Oddly that contrast is best covered in the next section, where you'll see them together.\n<h2>Mixed Directionality</h2>\nText with mixed character sets is very common across the internet. A big part of this is that HTML and HTTP are both run on the Latin script (hell, they're all English and English abbreviations). This means the HTML markup and things like URLs need to co-exist with right-to-left content in many places. Website names are a perfect example of that. The basis of directionality in Unicode is that all <strong>directionality is defined on a per-character basis</strong>. I'll start with an example and explain from there.\n<pre>Text: ab\u0627\u0628ab\n\nUnicode Bytes     Letter\n------- --------- ------\nU+0061  0x61      a\nU+0062  0x62      b\nU+0627  0xD8A7    \u0627\nU+0628  0xD8A8    \u0628\nU+0061  0x61      a\nU+0062  0x62      b</pre>\nThere is an <a title=\"bidi layout algorith\" href=\"http://unicode.org/reports/tr9/tr9-15.html\" target=\"_blank\">algorithm for bidirectional character layout</a>, but I find it's easiest to think of it as: A group of character with the same directionality are processed by the layout engine together. This means that a group of right-to-left characters surrounded by left-to-right characters will be reversed, as a native speaker would expect. This also means that a single character of a different directionality does not break those around it (like a\u0628c). I'll use bytes so it's clear what I mean. If you look at the example above you'll see that after <em>0x62</em> you next see <em>0xD8A8</em>, which is the fourth character. When the layout engine reaches the third character (<em>0xD8A7</em>) it finds a directionality of right-to-left, then the fourth character (<em>0xD8A8</em>), which is also right-to-left. Since these are both right-to-left they are displayed as such. The following character is once again <em>0x61</em>, which is again a change in directionality.\n<h2>Arabic Complications to Layout</h2>\nI started working on this post because I have an interest in languages and computers. But probably more so because I speak some Arabic and it has some interesting text layout issues. Right-to-left is one of the most obvious issues, but the character connection is one that I have seen unimplemented most often (Adobe Flash, TextMate, etc.). Arabic is written with characters that connect to the subsequent character, sort of like cursive in English. Arabic complicates that a bit more by having some characters that connection on both sides (like \u0628) and other that only connect on the right (like \u0648). This post isn't about Arabic letter forms but it shows where text layout engines are more complicated than people think. Let's look at one quick example of what characters I type versus what is displayed.\n<pre>I Type (and store in a file): \u0644 \u0644 \u0644\n\nUnicode Bytes     Letter\n------- --------- ------\nU+0644  0xD984    \u0644\nU+0644  0xD984    \u0644\nU+0644  0xD984    \u0644\n\nDisplayed As: \u0644\u0644\u0644\n\nWhich are actually the characters \u2026\n\nUnicode Bytes     Letter\n------- --------- ------\nU+FEDF  0xEf889F  \ufedf\nU+FEE0  0xEF88A0  \ufee0\nU+FEDE  0xEf889E  \ufede</pre>\nAs you can see the characters stored and the characters displayed are all different. This choice to use different characters in order to make the letters connect is done by the layout engine. Writing this was actually quite hard since I did it in TextMate and it uses a text layout engine that does not connect characters.\n<h2>Language Is More Than Characters and Words</h2>\nThis was a very simple explanation of right-to-left character display. Nothing revolutionary but the idea was to point out that applications usually fall between the two initial reactions of dread and the expectation it will all \"just work because I've gots teh Unicode\". This post leaves out the very large localization issues that right-to-left languages create. I'll use web design for some examples, since it's something I know and something you're likely to know as well:\n<ol>\n\t<li>Should the sidebar still be on the same side? Think back to how you chose a side.</li>\n\t<li>Your CSS <em>float:</em> attributes are probably wrong.</li>\n\t<li>Your header items are in the wrong order.</li>\n\t<li>Your images may point the wrong way.</li>\n</ol>\nThis skips the cultural issues of Hebrew and Arabic localization (obviously different in many ways), but I want to touch a bit on that last one since it's a favorite of mine. Imagine the stock photo of a soaring business chart with the climbing red line and no scale. Now imagine if you read from right-to-left, and thus thought of the X-axis as reversed \u2026 you just told everyone you're failing more every day. Good job.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "17", 
            "link": "http://mzsanford.wordpress.com/2009/02/06/character-direction/", 
            "name": "character-direction", 
            "post_date": "2009/02/07 05:54:48Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Character Direction for Developers"
        }, 
        {
            "categories": [
                "Languages", 
                "Programming"
            ], 
            "comments": [], 
            "content": "Tokenization refers to splitting any data into chunks, and in the case of this post I'm focusing on splitting text into words. The process of turning free-form text into individual pieces of information (word, phrases, sentences, etc) is something that natural language parsing (NLP) researchers have been interested in for years. There is a whole field of study on the subject that this post does not hope to even touch on. For developers with no language experience this process is usually overlooked as absurdly simple, I mean <code>split(/\\W+/)</code>, right? If you nodded then this is for you. If you think that was overly simple this will probably be old hat.<!--more-->\n<h2>English Can Be Easy</h2>\nEnglish, as my native language, turns out to be one of the easier languages to do basic tokenization on. By basic I actually refer to <code>split(/\\W+/)</code>. This will split a sentence into words and it will be correct in many cases. Like everything else in English, it's pretty much defined by its exceptions. Hyphenated words are a pretty obvious stumbling block but there are some others as well.\n<h2>English Can Be Hard</h2>\nDepending on what you're planning to use data for there is some more processing that might be needed. Data normalization is a normal step in almost every process so I don't think anyone will find that surprising. Like any other normalization this is very dependent on what you plan to do, and this is where English can get tricky. Here are a few of the common normalization tasks with words:\n<ul>\n\t<li>remove \"stop words\" (a, the, and, but, etc) since they don't really tell you much.</li>\n\t<li>removing plurals and other sufficies, usually via <a href=\"http://en.wikipedia.org/wiki/Stemming\">stemming</a>. This can be pretty hard to get right, especially if you have a vocabulary of jargon.</li>\n</ul>\nThe same thing goes for many other european languages. What varies between these languages isn't the delimiters, which are still spaces and punctuation, but instead the amount of normalization needed. While your project might not need stemming for English it's possible that the vowel-changes in German conjugation will require it. One other small detail people skip is that <code>\\w</code> (or the inverse, <code>\\W</code>) may not match accented characters depending on your programming environment.\n<h3>A Quick German Digression</h3>\nWhile talking about normalization of languages people may or may not speak it's always good to give an example of something language-specific. I speak German so it's a natural choice for an example. I implied above that the major difference between English and other european languages is normalization, but there is a German specific issue that blurs the line between tokenization and normalization \u2026 decomposition.\n\nGerman is pretty notorious for having long, silly sounding words. What people often miss is that these are actually compounds. For example sliced sugar beats used during the process of sugar processing is called \u00a0zuckerr\u00fcbenschitzel:\n\n<img class=\"aligncenter size-medium wp-image-33\" title=\"zuckerr\u00fcbenschitzel\" src=\"http://mzsanford.files.wordpress.com/2009/10/img_0288.jpg?w=225\" alt=\"zuckerr\u00fcbenschitzel\" width=\"225\" height=\"300\" />\n\nNow, that seems like a bit of a specialized word to me, however this was a label in a museum. You see, it's actually three words: zucker (sugar), r\u00fcben (beat), schnitzel (slices). So, while that's one token, it can be decomposed into 3 words \u2026 if you need to do that decomposition or not depends on your application. How you actually do that is a whole 'nother blog post.\n<h2>And CJK Is Always Hard</h2>\nSo, English can be hard to process depending on how you plan to use the data. Chinese, Japanese and Korean are pretty much always hard. Lately I've been working on the problem of Japanese and I'll do a full post on that at a later date. For English speakers, consider how you would process things if there were no spaces between words. The three writing systems in Japanese provide some clues but the essence of the problem is the word delimiters. I'll leave at this for now and do a post on Japanese tokenization later.\n<h3>A Japanese Digression</h3>\nWithout going into the nitty gritty of Japanese tokenization there is a pretty good example that comes to mind. Imagine a <a title=\"My Work\" href=\"http://twitter.com\">system</a> that lets you post short messages, and that many of those contain links. Now assume that at display time you want to automatically link the URLs that appear in the message. Now, here we go in Japanese (well, some Japanese characters laid out like a short message):\n<pre>\u306e\u306ehttp://example.com/\u306e\u306e</pre>\nAuto-linking requires that you identify the URL in the midst of all of the other text. While this is a pretty simple problem I should point out that the default auto linking in many languages and libraries do not handle this correctly. The easiest route is to use what you know about valid URL characters (simplified to host name only, other URL components are left to people willing to read the RFC):\n<pre>message.gsub(/http:\\/\\/[a-z0-9-\\.]+\\.[a-z]{2,}\\/?/i) {|url| \u2026 }</pre>\n<h2>Arabic (you knew it was coming)</h2>\nI've mentioned Arabic before and it's normally either ignored when talking about internationalization or it's skipped after some hand waving about right-to-left. Arabic is a phonetic language every bit as much as English (arguably more so \u2026 I'm looking at you <em>faux pas</em>) with an alphabet and spaces between words.\u00a0To some extent it's just like the european languages I mentioned above \u2026 almost.\n\nArabic relies very heavily on prefixes and suffixes connected directly to words. The most ubiquitous of these is the definite article \u0627\u0644 (Al-, meaning \"the\"). It's questionable if this is strictly a tokenization problem, but it does mean that using Arabic data without specific normalization is of very limited usefulness. Possession is represented by a suffix attached directly also, as are a myriad of other things. This is sort of like the German example above, only that it effects so many words that you'll have to tackle it sooner if you plan to find meaningful data.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "22", 
            "link": "http://mzsanford.wordpress.com/2009/10/15/tokens-are-not-just-for-chuck-e-cheese/", 
            "name": "tokens-are-not-just-for-chuck-e-cheese", 
            "post_date": "2009/10/15 02:53:00Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Tokens are not just for Chuck-e-cheese"
        }, 
        {
            "categories": [
                "Programming"
            ], 
            "comments": [], 
            "content": "Unicode support in Ruby doesn't get much attention. Most of the information about it focuses on MySQL more than it does on actual Ruby support. Ruby can read and write Unicode data without much trouble but actually working with it, and moreover making sure it does not get corrupted, is one of the lesser visited back-alleys of Ruby. Hopefully I can make some more time to blog about other Ruby/Unicode interaction but I have to start somewhere so Regular Expressions are as good a place as any. Perhaps better since they're their own dark art.\n<h1>Word To Your Mother</h1>\nWhen it comes to Unicode and Regular Expressions the <code>\\w</code> escape (for matching word characters) is the most commonly misused. Ruby makes this situation all the more difficult by changing behavior based on a global variable, <code>$KCODE</code>.\n\nWhen most programmers use the <code>\\w</code> escape they mean <code>[a-zA-Z0-9_]</code> (which is how POSIX defines <code>[[:word:]]</code>) and Ruby will work like that \u2026 until the <code>$KCODE</code> changes. Once <code>$KCODE</code> is set to <code>u</code> (Unicode) the <code>\\w</code> escape starts matching any word character in any langage, including things like \u0634 or \u3333. Check out <a title=\"Gist 274731 - Unicode Regex with $KCODE\" href=\"http://gist.github.com/274731\">gist 274731</a> for a working example, or the <a href=\"http://github.com/mzsanford/oauth/commit/470c08ec3a9b55e85a6f5bbc730d387f3bf7afa2\">similar patch to the OAuth gem</a>, which shows that this isn't only theoretical. It isn't just complex things like OAuth request signatures, imagine this as a validation on a user name (which would allow some of the commonly confused characters, like \u00ed).\n<h1>Space (<code>\\s</code>): The Final Frontier</h1>\nAnother common misconceptions about Regular Expressions is that the <code>\\s</code> escape handles all space characters. While it does match more than \"<code> </code>\" (<code>U+0020</code>)\u00a0alone it's by no means complete. There are a multitude of space-like characters in the Unicode standard but when it comes to natural language there is a small subset that will suffice in the vast majority of cases. In fact, <code>U+0020</code> will cover most languages but fails on east Asian ideographic alphabets (which don't space separate words, as I've <a href=\"http://mzsanford.wordpress.com/2009/10/15/tokens-are-not-just-for-chuck-e-cheese/\">mentioned in the past</a>) where the full-width space (<code>U+3000</code>) is used.\n\nIf you're well versed in Regular Expressions you might consider POSIX character classes the answer to the problem. The POSIX standard defines the longer named character class <code>[[:space:]]</code> but it's a direct equivalent to the <code>\\s</code> escape. For a practical demonstration check out <a title=\"gist 274725 - Unicode spaces\" href=\"http://gist.github.com/274725\">gist 274725</a> over on github.\n<h1>Matching Numbers</h1>\nNot every country and language uses the same numeral system. One thing that makes programming slightly easier is that the arabic numeral system (<code>0123456789</code>) has become more or less the standard throughout in computing world. This convenience has allowed Ruby (and most other languages) to ignore the alternate numbering systems Unicode allows. A rather contrived example is that of braille but a much more common one is the numeral system used in Egypt, the so-called \"Arabic - Indic\" digits (<code>\u0660\u0661\u0662\u0663\u0664\u0665\u0666\u0667\u0668\u0669</code>). As you can see from <a title=\"gist 274737 - Unicode digits regex\" href=\"http://gist.github.com/274737\">gist 274737</a> on github the <code>\\d</code> escape\u00a0does not match any of these (nor does <code>[[:digit:]]</code>)\u00a0and <code>String#to_i</code> doesn't handle them either. Again, the good news is how prolific the arabic numeral system has become.\n<h1>Conclusion</h1>\nNo programming language handles Unicode perfectly, and Regular Expressions are very often problematic corners of Unicode support. This isn't Ruby specific and to be totally fair Ruby does a better job than some others. Like all posts this isn't exhaustive as much as an introduction to some of the most common issues. If you're interested in more information feel free to contact me on Twitter (<a title=\"@mzsanford on Twitter\" href=\"http://twitter.com/mzsanford\">@mzsanford</a>) or <a title=\"Apply to work on i18n at Twitter\" href=\"http://bit.ly/7PL1J3\">apply to work with me</a> on the interesting problems I'm finding every day.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "44", 
            "link": "http://mzsanford.wordpress.com/2010/01/12/unicode-with-ruby-regular-expressions/", 
            "name": "unicode-with-ruby-regular-expressions", 
            "post_date": "2010/01/12 04:58:18Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Unicode with Ruby - Regular Expressions"
        }, 
        {
            "categories": [
                "Culture", 
                "Movies"
            ], 
            "comments": [], 
            "content": "After reading Alex Payne's post on heroism (<a title=\"Don't Be A Hero - al3x.net\" href=\"http://al3x.net/2010/01/09/dont-be-a-hero.html\">Don't Be A Hero</a>) I have to say I was a little irked. I disagree somewhat on the details of what defines a hero in this context and that seems to be the crux of my discomfort. I don't think hero's have to work until four in the morning. Nor do I think a hero creates inherently lower quality software. A hero is someone so dedicated and passionate about what they are doing that they are willing to work hard and deliver when other people are not (and for some people, what they are passionate about is not low-quality \"feature work\"). For some \"heros\" this becomes late nights, for others early mornings, and for still others it's a during the day activity with no extra time. I'll be honest, that last case is pretty rare, because the passionate usually see time as flexible and success as a rigid goal.\n\nI was never really sure how to some up my feelings on the post until last night. Oddly, it was the <a title=\"Eye of The Tiger - Persepolis\" href=\"http://www.youtube.com/watch?v=rlIAmCfHzbg\">Eye of The Tiger scene in Persepolis </a>that enlightened me. I've seen Rocky many times \u2013 and even once in the last few weeks \u2013 but somehow seeing that well-worn scene re-used highlighted my feelings. What's great about Rocky is that it gives me a way to sum up not just The Hero, but also the personalities that often surround them.\n<!--more-->\n<h2>The Supporter (Adrian)</h2>\nThe role of support is one that is often overlooked but shouldn't be marginalized. Many would-be heros fail because nobody is there to provide the unwavering support needed to keep up the hard work and dedication. While The Hero does things out of a sense of passion even that can be worn down by the continual hardships created (See: Anti-the-hero later in this post). Without The Supporter's positive support it's easy to get discouraged. This positive support contrasts the criticism of The Catalyst (more on that next) to create a balance that sustains The Hero. The role of The Supporter is so obvious there is not much to add other than it's a small but critical requirement.\n<h2>The Catalyst (Mickey)</h2>\nThe Catalyst is someone unfazed by heroism who pushes the hero to continue. This person is key in that they provide the criticism. This is the criticism discussed previously by Alex (<a title=\"Criticism, Cheerleading, and Negativity - al3x.net\" href=\"http://al3x.net/2009/12/06/criticism.html\">Criticism, Cheerleading, and Negativity</a>) and constitutes the best undiluted feedback The Hero is going to get. The Catalyst is usually the only person as hard on The Hero as they themselves are. Without The Catalyst, The Hero will plateau at some point where they feel they are trying to make it but they're still a bum. The pre-catalyst stage is essentially where the movie Rocky begins.\n<h2>Anti-the-Hero (Paulie, not to be confused with an anti-hero)</h2>\nI've often said: \"People love to see an underdog win. Almost as much as they want to see a hero fail\". I started saying this early in my working life as what I thought was great satirical hyperbole. It turns out that long after the fact I've only confirmed it is true in some cases. Throughout Rocky Paulie acts in selfish and crude ways that undermine the success of Rocky and the happiness of his own sister. Paulie is a believable character because there are people like this throughout our lives \u2026 they are not directly against us but through their action they continually derail us.\n\nI'm not saying that anyone against heroism is out to stop The Hero. In some cases it's simply a misunderstanding of why The Hero exists. It's not to be a martyr, nor to prove something to someone. It's simply to prove to themselves that they can go fifteen rounds with Ap0llo Creed and come out on the other side. There is an important point in the finale of Rocky, he doesn't win the fight. It's about passion, not success.\n<h2>The Hero (Rocky)</h2>\nAt the end of the film, after the fight but before finding out he lost in a split decision, Rocky has the following to say to Apollo Creed:\n\n<strong>Apollo Creed</strong>: Ain't gonna be no rematch.\n<strong>Rocky</strong>: Don't want one.\n\nThe Hero does not exist to please you. The Hero does not exist to feel better than you. The Hero exists to feel better than they did when they got up this morning. Where Alex and I can certainly agree is that The Hero is a detriment if he or she is focused on fire-fighting and slap-dash software development. Where we seem to diverge is that I have seen many a hero who's passion is high quality software AND features. This issue isn't heroism, it's heroism with the wrong focus.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "64", 
            "link": "http://mzsanford.wordpress.com/2010/02/22/on-heroism-%e2%80%93-a-rocky-analogy/", 
            "name": "on-heroism-%e2%80%93-a-rocky-analogy", 
            "post_date": "2010/02/22 18:59:29Z", 
            "status": "publish", 
            "tags": [], 
            "title": "On Heroism \u2013 A Rocky Analogy"
        }, 
        {
            "categories": [
                "Languages", 
                "Programming"
            ], 
            "comments": [], 
            "content": "<p style=\"clear:both;\">Like all aspects of computers Unicode has its own security issues. And like all Unicode issues most engineers spend their entire professional career trying to avoid dealing with them. It's ok, you can be honest, I understand. When I gave my talk about Twitter International at Chirp (the Twitter developer conference) I mentioned some of these issues. After that talk I was surprised how many people who know more about internationalization than I do said they hadn't considered some of these issues.</p>\n<p style=\"clear:both;\">I'm not going to go into a ton of detail since I'm not a security researcher. I am, however, and engineer focused on international and as such I think it's my business to know where my push to internationalize everything reaches it's limit. If you're in a similar position, pushing people to internationalize, you should make sure you fully understand these issues. If you push people to internationalize and in the process create security flaws you'll be spending your credibility. Don't spend it on this \u2013 the cost is too high.</p>\n<!--more-->\n<p style=\"clear:both;\">I recommend the awesome paper <a title=\"Unicode Technical Report #36 - Security Considerations\" href=\"http://www.unicode.org/reports/tr36/\" target=\"_blank\">Unicode Security Considerations</a> (Unicode Technical Report #36) as it served as the basis for this whole post. The problem is, Technical reports are tedious to read so I'm adding this teaser. Here are some highlights (lowlights?) of Unicode security:</p>\n<p style=\"clear:both;\"></p>\n\n<h1>Character Ambiguity</h1>\nThe most common security issue I've seen with internationalized products is character ambiguity. This same property is commonly used for spam but it also poses security risks. Character ambiguity is using characters from different writing systems that look very similar to the expected characters. People see what they expect to see \u2026 this is the enemy.\n\n[caption id=\"attachment_83\" align=\"aligncenter\" width=\"300\" caption=\"Image from flickr\"]<img class=\"size-medium wp-image-83 \" style=\"text-align:center;display:block;margin:10px;\" title=\"Many bags look alike\" src=\"http://mzsanford.files.wordpress.com/2010/05/2144235519_0819f7b619.jpg?w=300\" alt=\"\" width=\"300\" height=\"225\" />[/caption]\n<p style=\"clear:both;\">The security risk of ambiguity is mostly related to impersonation. Impersonation is the underlying mechanism for phishing, which we can all agree is a major security problem. While ASCII alone contained ambiguity (Capital I looks an awful lot like lower case L in many fonts) Unicode expands the problem. For example, full-width latin characters, like \"\uff46\uff4f\uff4f\", in place of the expected latin characters, \"foo\". Within a sentence that's easy to spot, but what about \"\uff2f\" by itself, like \"David \uff2f. Selznick\"? <a title=\"Cyrillic Unicode Block - Fileformat.info\" href=\"http://www.fileformat.info/info/unicode/block/cyrillic/utf8test.htm\">Cyrillic adds a host of characters</a> very easily confused with latin text.</p>\n<p style=\"clear:both;\">This issue has implications beyond the impersonation of people. Any time you present a user-provided string to identify a given entity you run the risk of \"impersonating\" that entity. That's a little too abstract, let's ask Network Solutions and <a href=\"http://paypai.com\">PaypaI.com</a> \u2026 oh, <a title=\"Scam\" href=\"http://www.zdnet.co.uk/news/security-management/2000/07/24/paypal-alert-beware-the-paypai-scam-2080344/\">did I say PaypaI.com</a>? In many fonts, including most browser defaults, that's almost indistinguishable. With the introduction of International Domain Names (IDN) there is a very real concern about this. Where does g\u043e\u043egle.com go? Did you notice the two Cyrillic \u043e's? Good news on this front specifically is that <a href=\"http://www.ripe.net/ripe/meetings/ripe-52/presentations/ripe52-dns-ican-idn.pdf\">ICANN is more than aware of the issue and is on it</a>.</p>\n<p style=\"clear:both;\"></p>\n\n<h1>Bi-directional Phishing</h1>\n<p style=\"clear:both;\">As somebody who speaks a little Arabic, and generally geeks out about Unicode and right-to-left this is a personal favorite. It turns out that in addition to the built-in Unicode character direction there are also some characters for explicitly controlling character direction. This is a case where adding support for something produces some unexpected security issues. Packet Storm Security has a great, easy to read <a href=\"http://packetstormsecurity.org/papers/general/righttoleften-override.pdf\">paper on the subject</a> [PDF].</p>\n<p style=\"clear:both;\">By forcing the direction you can make 'foo' appear as 'oof', which seems innocuous enough. Where things get interesting are when programs try to augment text with auto-linking. I've been doing some Ruby on Rails work and often times project use the auto_link() helper function. If a user provides the text that is being passed into auto_link() to can end up with:</p>\n\n<blockquote style=\"clear:both;\">\n<pre>auto_link(\"Change your password at #{[0x202E].pack('U')}http://MALWARE.COM/long/and/impressive/secure/looking/url/here/moc.knabitic.www://ptth\")</pre>\n</blockquote>\n<p style=\"clear:both;\">Which in both Firefox and Safari looks like so:</p>\n<p style=\"clear:both;\"><img class=\"alignnone\" title=\"Right to Left auto_link spoof\" src=\"http://img.skitch.com/20100515-cb281jx47tak78t8wxnp4qkp5p.jpg\" alt=\"Displaying a malware link as Citibank\" width=\"843\" height=\"36\" /></p>\n<p style=\"clear:both;\">Note that this still links to malware.com.</p>\n<p style=\"clear:both;\"></p>\n\n<h1>Conclusion</h1>\n<p style=\"clear:both;\">Hopefully this was educational and not too dry. I recommend reading the <a title=\"Unicode Technical Report #36 - Security Considerations\" href=\"http://www.unicode.org/reports/tr36/\" target=\"_blank\">Unicode Security Considerations</a> document as well as the closely related <a title=\"Unicode Security Mechanisms - Technical Standard #39\" href=\"http://www.unicode.org/reports/tr39/\" target=\"_blank\">Unicode Security Mechanisms</a> document if you're interested in other possible security issues. I didn't even touch on the lower level buffer overflow errors in text processing \u2026 most people reading this are using a sufficiently high level language such that they assume they can ignore that.</p>\n<br class=\"final-break\" style=\"clear:both;\" />", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "80", 
            "link": "http://mzsanford.wordpress.com/2010/05/15/unicode-security/", 
            "name": "unicode-security", 
            "post_date": "2010/05/15 19:33:21Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Unicode Security: Yes, there is such a thing"
        }, 
        {
            "categories": [
                "Culture"
            ], 
            "comments": [
                {
                    "author": "Matt Auckland", 
                    "author_email": "matt@ge3k.co.uk", 
                    "author_ip": "93.97.184.10", 
                    "author_url": "http://www.twitter.com/mattauckland", 
                    "content": "Good read. From someone who is in the early stages of building a web start-up I can relate.\n\nAt this stage of a start-up your head can be filled with thoughts of what could be, investment, and ideas of writing mad code. Very much being on the crest of the wave.\n\nBut it's also important to get some focus, and try and steer your ship in the right direction, because waves have a tendency to break, and you don't want to be heading in the wrong direction when they do.", 
                    "post_date": "2010/08/13 13:32:35Z"
                }
            ], 
            "content": "I've been working for a pretty early stage and popular start up for a few years now and I've learned some things. None of what I've learned is news to people who have been through the start up mania, and I bet there are better posts out there on the internet. These are my personal ramblings about my experience and might not reflect anyone else's experience. Having said that, when I was making my decision to join a start up I wanted an informal description of this arc and all I found where venture capitalists and people yearning for the bygone '90's bubble. I'm neither of those. I'm just a guy who likes to play with badly formed analogies.\n\nStart up life is complicated so no one analogy really explains it all. Instead I've opted to break it into three phases, all alike in dignity. It's not like there is a day where you switch from one phase to the next \u2026 and I'm not even sure I could spot these again if I were in the middle of them. This is a hindsight look at the last two years. The craziest and possibly best years I've known.\n<!--more-->\n<h1>It All Starts with Prometheus</h1>\n<p style=\"clear:both;\">When Prometheus stole fire from the gods he didn't sell it to his neighbor. He didn't barter with it or tell the person next to him about \"<em>the exciting investment opportunities in state-of-the-art home heating and illumination</em>\". No, he <strong>gave</strong> it to humanity. I joined a start-up when it was still very small and making no money at all. At the same time we were becoming quite popular and busily working to stay online. I'm not saying we brought something as critical as fire to man, but what I am saying is that we didn't show up looking like P.T. Barnum and trying to bilk the suckers. We showed up with what we could muster and gave it up for people to use as they like. And boy did they use it \u2026 and in ways we never imagined. Looking back on it the Prometheus myth would be more fitting if he was burned badly while delivering fire to man, but that's another story.</p>\n<p style=\"clear:both;\">To me the point is that it starts with an idea, yearning to spread, and making that idea available for free is a good start. Selfishly: you are more free to experiment when money isn't your biggest worry. Pragmatically: Building a product people love will result in more people spending time with your product and becoming the people to whom you market your money-making idea. Bring the fire for free now and when you see they use it to see in the dark start making oil lamps to sell (or stoves to cook).</p>\n\n<h1>On to the Industrial Revolution</h1>\n<p style=\"clear:both;\">It's hard to think of the Industrial Revolution without thinking of profit and loss, especially after the \"free fire\" talk above but that's what I need to ask you to do. Trust me, we're still in the free period of the start up product but the Industrial Revolution has a good lesson. This phase of the arc is about the accumulation of \"<a href=\"http://en.wikipedia.org/wiki/Technical_debt\"><strong>technical debt</strong></a>\".</p>\n<p style=\"clear:both;\">During the Industrial Revolution the skies were filled with black smoke from coal fires. Those coal fires were powering some of the greatest inventions of the 18th and 19th centuries and altered the lives of the people living in those times, and the history of the world in some cases. The focus of all manufacturers was getting their product out to the people, often ignoring any consequences. Start ups are less reckless and unlike Industrial Revolution factories they don't endanger workers' lives or the environment, but they leave a wake of refuse all the same. That refuse is called \"technical debt\" and is sometimes the code left over by late-night, under-fire fixes but more often than not it is the design work done when the product was being use differently that it would end up being used in the end.</p>\n<p style=\"clear:both;\">This filling of your office sky with coal smoke is a good thing, actually. While there will be a time when you look back on it and realize you were rash, I would argue you could never have made it to that vantage point without a little rash action.</p>\n\n<h1>Renewable Energy: The Promised Land</h1>\n<p style=\"clear:both;\">I'll tie the second and third phases of this arc together, since they're very related. In the real worlds there came a point where we started to talk about \"peak oil\" and \"climate change\" and ever since then we've looked back on the Industrial Revolution like a youthful indiscretion. Something we would do better if we had it to do again. We've more or less painted ourselves into a corner when it comes to energy and environmental issues and now we're trying to fix it. Start ups are no different in my experience.</p>\n<p style=\"clear:both;\">During the \"Industrial Revolution\" phase of the start up there was furious design and implementation work. We didn't completely know where we were headed but we knew we wanted to get there and find out. Now that we've reached a point where we can see what the product is we can look back over the scorched earth behind us and wonder what we were thinking. Well, if we were busy wondering back then we wouldn't be able to think about how to fix it, we would have failed, so I'm glad we did what we need to survive.</p>\n<p style=\"clear:both;\">So we're in search of the promised land of renewable energy, but unlike the real world we can cleanup all of the mess we've made. We want something that does not pollute our experience (or code base) but can sustain itself. This means fixing the things we've created in haste, turning a good product into a sustainable business, and continuing to do what made us a success: focusing on users. We have a group of great people evaluating a bevy of great options and I believe we'll manage a balance we can be proud of. Maybe in the future I'll add a fourth phase about utopia \u2026 or the after life. My bet is on utopia but life can be unpredictable.</p>", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "81", 
            "link": "http://mzsanford.wordpress.com/2010/08/12/my-life-in-the-start-up-arc/", 
            "name": "my-life-in-the-start-up-arc", 
            "post_date": "2010/08/12 17:06:18Z", 
            "status": "publish", 
            "tags": [], 
            "title": "My life in the start up arc"
        }, 
        {
            "categories": [
                "Culture"
            ], 
            "comments": [], 
            "content": "I have many friends who are vegetarian to one degree or another and I'm happy to accommodate that. I respect their choice in the same way they respect mine. In asking around about people's dietary restrictions over the years I've found a group who annoy me: The Dishonest Omnivore.\n\nI am an omnivore and I'm not ashamed. I'm also not squeamish about where my food comes from. I know that pork used to be a pig, beef a cow. I can't say I love the feel of raw chicken in my hands. What I can say is that I like the taste of chicken more than I dislike dealing with it in the raw \u2026 and because of that I'm unashamed to be an omnivore.\n\n<!--more-->\n<h1>Burgers Shaped Like Cows</h1>\nAnybody who has talked about food with me has heard my rant about burgers shaped like cows. Well, that pretty much the gist of this post and it sums up my feelings. If you order a hamburger you need to be comfortable with the fact you're eating what was formerly a cow (or, depending on where you order it, several different cows). If you ordered and someone told you the cow's name was \"Bessy\", would you order something else? If so, perhaps vegetarianism is for you. Vegetarian food is just as tasty, sustaining and filling as the omnivore diet.\n\nAs time has progressed we've become farther and farther removed from the source of our food. Where our parent or grandparents might have raised live stock, today the vast majority of us don't have that sort of connection to our food source. There has been a local food movement brewing, mostly focused on fruits and vegetables. This movement has been about distance in the traditional land area sense \u2026 I want less distance in the mental sense. I want to think about the previous form of my food. Be it vegetable:\n\n<a href=\"http://mzsanford.files.wordpress.com/2010/05/800px-brusselssprouts-onvine.jpg\"><img class=\"aligncenter size-medium wp-image-104\" title=\"Brussels Sprouts on the Vine\" src=\"http://mzsanford.files.wordpress.com/2010/05/800px-brusselssprouts-onvine.jpg?w=300\" alt=\"Brussels Sprouts on the Vine\" width=\"300\" height=\"194\" /></a>\n\nor animal:\n\n<a href=\"http://mzsanford.files.wordpress.com/2010/05/500px-british_pork_cuts-svg.png\"><img class=\"aligncenter size-medium wp-image-105\" title=\"British Pork Cuts\" src=\"http://mzsanford.files.wordpress.com/2010/05/500px-british_pork_cuts-svg.png?w=300\" alt=\"British Pork Cuts\" width=\"300\" height=\"155\" /></a>\n\nBut let's be honest \u2013 nobody is squeamish about what a vegetable looked like in the field.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "98", 
            "link": "http://mzsanford.wordpress.com/2010/05/16/the-honest-omnivore/", 
            "name": "the-honest-omnivore", 
            "post_date": "2010/05/16 03:51:56Z", 
            "status": "publish", 
            "tags": [], 
            "title": "The Honest Omnivore"
        }, 
        {
            "categories": [
                "Programming"
            ], 
            "comments": [], 
            "content": "So the new Twitter redesign (a.k.a. #NewTwitter) is out in the wild at last, even if it's only a small percentage of users. Soon enough we'll all have access but even before that I wanted to write about customizing #NewTwitter using Grease Monkey. Much has been said about the new right side \"Detail Pane\" real estate as a platform but I don't know about any of that. I suspect that annotations and the Details Pane will be a match made in heaven but that's not something I heard at the office, just my personal view as a former Platform team member, and former 3rd party Twitter developer.\u00a0What I'm interested in <em>right now</em> is customizing the Details Pane for myself using Grease Money.\n\n<!--more-->\n\nI know that Twitter had to limit who they display content from for a myriad of reasons. I'm not privy to the reasons but I know from the public discussion around\u00a0<a href=\"http://www.avc.com/a_vc/2010/04/the-twitter-platform.html\">previous blog posts</a> that Twitter is sensitive about injuring 3rd party developers. When it comes to mash-ups, which is essentially what this is, most developers I know would argue that any site with an open API is fair game. With that moral relativism out of the way I'll get down to the business at hand.\n<h2>Adding a new media type</h2>\nMaybe your you and your friends use an unsupported photo posting site. Maybe it's video. Maybe it's something I haven't yet thought of. Whatever it is, here is an example of adding a new media hosting site. This specific technique works with any site providing content from a URL based on the short-url component. For my example I'm using images from the image hosting site img.ly. I'll start with a code listing and then break it down:\n<pre>// ==UserScript==\n// @name          Twitter Details Pane - Media Type support example\n// @namespace     http://mzsanford.com/\n// @description   Example script to display a spcific media type\n// @include       http://twitter.com/*\n// @include       https://twitter.com/*\n// ==/UserScript==\n\n(function(){\n\n    window.addEventListener('load', function() {\n      unsafeWindow.twttr.mediaType('twttr.media.types.Imgly')\n\n      .url('http://img.ly')\n      .matcher(/\\b(?:https?\\:\\/\\/)?img\\.ly\\/(\\S+)/g)\n\n      .icon('photo')\n\n      .process(function(slug, cb) {\n        slug = slug.replace(/\\/$/, '');\n        this.data[\"id\"] = slug;\n        cb();\n      })\n\n      .methods({\n        html: function(cb) {\n          var t = '&lt;img src=\"http://img.ly/show/medium/{id}\" /&gt;'\n          cb(unsafeWindow.twttr.supplant(t, this.data));\n        }\n      });\n    }, true);\n})();</pre>\nI'm going to skip the Grease Monkey boiler plate and get right to line 11. You can't call into the #NewTwitter Javascript environment until it's loaded (duh) so I setup a window load handler to run my code. Now the magic begins. Using some information <a href=\"http://twitter.com/hoverbird\">@hoverbird</a> <a href=\"http://gist.github.com/584797\">posted on GitHub</a> and Grease Monkey's unsafeWindow I was able to execute my own Javascript code in the #NewTwitter environment. This code uses Twitter's twttr.MediaType system to register a new URL pattern and how it is displayed.\n\nThe \u00a0url() and matcher() functions seem pretty straight forward with the additional note that parentheses in the matcher pattern can be accessed by the process function. The icon() function takes one of three values: 'photo' (the little picutre), 'video' (which looks like film) and 'generic' (a little generic page icon) and is displayed on the timeline. The process function is run for the timeline entries and where you can stash away infomation found in the URL match for later on. And lastly the html method (defined using this odd methods({}) syntax) is where the actual data is rendered in the Details Pane.\n\nIf you had a JSONP API to work with you would want to make your call in the html method since it called when the Detail Pane is rendered. Calling in the process method would create a bunch of load on the other API for Tweets that the user never clicks on. That's not how friendly neighbors work.\n\nHopefully that was at least a little helpful for developing Grease Monkey scripts that work with #NewTwitter. I am also working on Details Pane interaction without a timeline icon but that will have to wait for a future post. If you have a suggested API to use for my next example (JSONP is easiest) drop a comment at the bottom.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "121", 
            "link": "http://mzsanford.wordpress.com/2010/09/19/grease-monkey-for-newtwitter/", 
            "name": "grease-monkey-for-newtwitter", 
            "post_date": "2010/09/19 23:47:20Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Grease Monkey programming for #NewTwitter"
        }, 
        {
            "categories": [
                "Culture", 
                "Twitter"
            ], 
            "comments": [], 
            "content": "If you've seen me talk at a conference or meet-up about Twitter you've likely heard about MC Hammer (<a href=\"http://twitter.com/mchammer\">@mchammer</a> on Twitter). Well, since I don't do that many speaking engagements I wanted to take a moment and record my story about about what MC Hammer taught me about Twitter \u2026 and I already worked there.\n\n<!--more-->\n<h2>The Twitter HQ Visit</h2>\nIn May of 2009 I had been working for Twitter for long enough that the then-common celebrity visits to HQ didn't seem out of the ordinary. Having said that, I worked remotely so these visits always seemed like an exotic treat when they coincided with my trips to SF. It was only the second time only of these visits was scheduled during one of my SF trips and it was going to be MC Hammer. To be honest I wasn't an MC Hammer fan even when he was huge and I thought it seemed like it was going to be a bit dull. I could not have been more wrong.\n\nMC Hammer started by talking about his own use of Twitter. He was one of our earliest high-profile users and we all knew he was an avid user. He is an amazing speaker and kept a group who were probably not fans glued to the talk. Hearing people tell the stories about how they use Twitter is always interesting. Most people stop at how they use it but Hammer talked about how he saw it changing the very business he was in. To explain that, let me follow the line of thought he had at the time.\n<h2>Hammer's Tale (my recollection, anyhow)</h2>\nIf you're making a music video you can <a title=\"#7 is MC Hammer\" href=\"http://en.wikipedia.org/wiki/List_of_most_expensive_music_videos\" target=\"_blank\">spend quite a bit of money</a>, and that is money spent by you and/or your label (if your label spends it you can bet they are going to want that back before you get paid). Now, you've spent this money and made a video which you then <em>give</em> to MTV. What does MTV do? They run your video surrounded by ads, for which they get paid. On cable networks who pay to carry the channel. The only way that money makes it back to the person who paid for and created the video is through exposure.\u00a0Well, money that comes in that way passes through a great many hands.\n<ul>\n\t<li><strong>Albums?</strong> Promotion, packaging and distribution take a chunk of that. Check out <a title=\"How music royalties work\" href=\"http://entertainment.howstuffworks.com/music-royalties6.htm\" target=\"_blank\">how that all works</a>.</li>\n\t<li><strong>Tours?</strong> It turns out carting all of that stuff around is expensive. Venues are expensive. And TicketMaster\u2122, just like MTV, are making money on both sides.</li>\n</ul>\nHammer has often rocked the boat in which the music industry sits, like providing <a href=\"http://venturebeat.com/2008/06/04/mc-hammer-offers-entrepreneurial-advice-to-intel-capitals-ceos/\" target=\"_blank\">advice to the Napster founder</a>, and his feelings about TicketMaster\u2122 were clearly of the same bent. Hammer, mobile phone in hand said (and I paraphrase),\n<blockquote>\"There will come a time when I can go to a stadium owner and say I want to put on a concert \u2013 ok, maybe not me, I'm not going to be playing stadiums, but Bruce Springsteen. Anyway: Bruce will say he can sell all of the tickets in the whole place with one Tweet [hold up his phone]. We don't need any TicketMaster\u2122. No booking agent. Just you, me and my followers buying tickets. Now, what kind of a deal will you give me on the concessions?\"</blockquote>\nDuring the Q&amp;A someone pointed out that the Bruce Springsteen story expected every artist to also be business savvy, which is unrealistic. Hammer's response, which will stick with me, was that there will always be agents and managers, \"There is always someone willing to do work like that for 20% of your take\".\u00a0In May of 2009 I thought this sounded really far fetched. I believed in our product but I never thought there would be a time where we could do anything like this.\n<h2>Enter the Future</h2>\nTime passed, I worked hard, and then Conan O'Brien came along. Conan sent a <a title=\"Hey Internet: I'm headed to your town on a half-assed comedy &amp; music tour. Go to http://TeamCoco.com for tix. I repeat: It's half-assed.\" href=\"http://twitter.com/#!/conanobrien/status/10326418664\" target=\"_blank\">tweet</a> with a link to buy tickets to his upcoming live comedy tour. Within hours the tickets were sold out. This didn't buy-pass traditional ticket agents, but there is no reason it couldn't have. This was only half way to the future Hammer talked about but it was the half I was (and still am) working on so it speaks to me. I am certainly convinced that Hammer was on to something. So this has left me feeling that Twitter will do more in the future than I can foresee today. But my main lesson is this:\n<blockquote>TicketMaster\u2122, watch your back \u2026 Justin Bieber doesn't need you.</blockquote>", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "131", 
            "link": "http://mzsanford.wordpress.com/2010/12/22/mc-hammer-showed-me-the-future-of-twitter/", 
            "name": "mc-hammer-showed-me-the-future-of-twitter", 
            "post_date": "2010/12/23 01:27:29Z", 
            "status": "publish", 
            "tags": [], 
            "title": "MC Hammer showed me the future of Twitter"
        }, 
        {
            "categories": [
                "Programming"
            ], 
            "comments": [
                {
                    "author": "mzsanford", 
                    "author_email": "mzsanford@gmail.com", 
                    "author_ip": "174.46.233.130", 
                    "author_url": "", 
                    "content": "Hi Kenneth,\n\n<b>On Security:</b>\n\nInteresting point on the security vulnerability. I can assume that most Ruby on Rails projects are running in some variant of this configuration so it requires less schema knowledge than you would think. The accented update case I used above does the lookup by ID so you cant force an incorrect lookup, but assuming you (a) allowed people to register with a foo@\u00e9xample.com, and (b) then did a lookup by email that ordered them such that the older came first and (c) did not error in the event of multiple results this could surface as a security issue. See:\n\n<code>\nselect * from foo where text = 'foo@example.com' order by id desc;\n+----+------------------+\n| id | text             |\n+----+------------------+\n| 10 | foo@\u00e9xample.com  |\n|  9 | foo@example.com  |\n+----+------------------+\n</code>\n\nFor point (b) I imagine an older account updating an email address would have the effect. For point (c) that is the default in ActiveRecord's find(:first) method so again, knowing someone runs Rails let's me know they could be open to this. On point (a), input validation saves the day. Yet again.\n\n<b>On Sorting:</b>\n\nYou can alter the collation at select time using the <code>COLLATE</code> keyword. This allows you to store anything but sort for display in a context sensitive way. My Japanese collation knowledge is minimal but I pulled the <code>utf8_general_ci</code>, <code>utf8_unicode_ci</code> and <code>utf8_bin</code> results for some Hiragana, Katakana and Kanji samples and pasted them side-by-side for a comparison:\n\n<code>\nSelect command: select * from foo order by text collate utf8_XXX;\n\nutf8_general_ci utf8_unicode_ci utf8_bin\n+----+------+   +----+------+   +----+------+\n| id | text |   | id | text |   | id | text |\n+----+------+   +----+------+   +----+------+\n|  1 | \u306e   |   |  2 | \u30b3   |   |  1 | \u306e   |\n|  4 | \u3070   |   |  3 | \u30b3   |   |  4 | \u3070   |\n|  2 | \u30b3   |   |  1 | \u306e   |   |  2 | \u30b3   |\n|  3 | \u30b3   |   |  4 | \u3070   |   |  3 | \u30b3   |\n|  5 | \u56fd   |   |  5 | \u56fd   |   |  5 | \u56fd   |\n|  6 | \u90e8   |   |  6 | \u90e8   |   |  6 | \u90e8   |\n+----+------+   +----+------+   +----+------+\n</code>", 
                    "post_date": "2010/12/28 23:19:06Z"
                }, 
                {
                    "author": "Ram Viswanadha", 
                    "author_email": "rviswanadha@gmail.com", 
                    "author_ip": "71.131.7.67", 
                    "author_url": "", 
                    "content": "\"The beauty of UTF-8 is that it is compatible with ASCII and ISO-8859-1 for the most common characters\"\nUhh .. a nit pick UTF-8 is not compatible with ISO-8859-1. ISO-8859-1 is from 0x00-0xFF which UTF-8 is only compatible with ASCII (0x00-0x7F). All code points in ISO-8859-1 from 0x80-0xFF need variable width encoding.", 
                    "post_date": "2010/12/28 23:06:08Z"
                }, 
                {
                    "author": "Kenneth", 
                    "author_email": "kenneth@kufluk.com", 
                    "author_ip": "174.46.233.130", 
                    "author_url": "http://kenneth.kufluk.com", 
                    "content": "Interesting.  Do people really still use Egyptian Hieroglyphs?  Awesome.  :D\n\nDoes the accent problem leave sites open to attack?  I can imagine registering on a site with an email address which is a duplicate of an existing address, but with an accent over one character.  The database might then update/read from the wrong record.  It's an edge case, sure, because it would depend on deep knowledge of the schema, but sounds possible if validation isn't correctly applied.\n\nThe biggest headache with UTF-8 storage for me was sorting Japanese strings.  How do you sort those, when your collation is set to utf8_bin?", 
                    "post_date": "2010/12/28 22:06:41Z"
                }, 
                {
                    "author": "mzsanford", 
                    "author_email": "mzsanford@gmail.com", 
                    "author_ip": "174.46.233.130", 
                    "author_url": "", 
                    "content": "Hi Ram:\n\nYou are correct. I meant to say that it was compatible with the most common characters form ISO-8859-1 (which also strove for ASCII overlap). I'll clarify that in the post \u2026 thanks for picking my nit :)", 
                    "post_date": "2010/12/28 23:22:43Z"
                }, 
                {
                    "author": "Quora", 
                    "author_email": "", 
                    "author_ip": "50.16.85.108", 
                    "author_url": "http://www.quora.com/Which-open-source-databases-boast-complete-Unicode-support#ans228702", 
                    "content": "<strong>Which open source databases boast complete Unicode support?...</strong>\n\nWhile Unicode support is probably not the only factor to use in deciding on a database, when it comes to Unicode support in a major open source RDBMS (MySQL or Postgres) it seems that Postgres has better support if configured correctly (See the post ab...", 
                    "post_date": "2011/01/06 01:57:08Z"
                }
            ], 
            "content": "I used MySQL for a great many projects over the years with the assumption that a charset of <code>utf8</code> and a collation of <code>utf8_unicode_ci</code> was going to support all of UTF-8 and that was all I need to do. I was sorely mistaken but there was no point in writing until now, because MySQL 5.5 has finally helped rectify the issue. Up until MySQL 5.5 (released December of 2010) the UTF-8 support was severely hobbled. With MySQL 5.5 the server can now support the full range of characters that UTF-8 allows but it's not the default behavior. There are still plenty of pitfalls for the na\u00efve developer starting out with MySQL.<!--more-->\n<h2>The root cause and how the problems surface</h2>\nIf you work on internationalization issues and use MySQL you've probably run into this. If not then it's only a matter of time until you run into it. This is the dirty little secret of MySQL before 5.5 \u2026 it only supports characters within the BMP (more on what that means in a moment). With Unicode <a title=\"Esoterica, anyone?\" href=\"http://www.unicode.org/charts/PDF/U13000.pdf\">6.0</a> over 50% of all characters are outside of the BMP so that's a big deal. To me it was a big deal before, but with Unicode 6.0 it's bigger and now people are starting to take notice. Supporting half of a character set is almost worse than not supporting it since it's difficult to figure out what's going to happen when you send data to the server.\n\nMost of the bugs caused by this poor UTF-8 support don't surface in English, and that's why many developers remain blissfully unaware of the problem. Having said that, this is not something that's only found when user's write in <a title=\"Deseret alphabet : all outside the BMP\" href=\"http://en.wikipedia.org/wiki/Deseret_alphabet\">Deseret</a> or <a href=\"http://www.unicode.org/charts/PDF/U13000.pdf\">Egyptian Hieroglyphs</a> (PDF), it also comes into play with Japanese names and some new Unicode characters like Emoji.\n\nThe MySQL defaults also have an effect on Unicode processing that affects the majority of European languages you're likely the try and target. This unsafe default \u00a0has a different root cause but I want to cover it here so the two issues are not confused with each other. Here are how some of the most common issue surface:\n<ul>\n\t<li>Attempting to update a record where a <code>varchar</code> column changed only by a single accent will return success but not save the change\n<ul>\n\t<li>This makes spelling corrections in record seem to \"not save\".</li>\n</ul>\n</li>\n\t<li>A row can be inserted successfully but when it is re-read the <code>varchar</code> column is empty or missing characters.\n<ul>\n\t<li>This is the case with the Ruby driver at least, probably others.</li>\n</ul>\n</li>\n\t<li>Unique constraints on <code>varchar</code> columns will fail despite different text if the differences are all outside of the BMP.</li>\n\t<li>You can't store the new Emoji characters, or they seem to disappear.</li>\n</ul>\n<h3>The supplementary character issue</h3>\nThe crux of the UTF-8 issue is rooted in the fact that UTF-8 is a <a href=\"http://en.wikipedia.org/wiki/Variable-width_encoding\">variable-width encoding</a>. The MySQL 5.1 implementation (like many others) was built on the assumption that a UTF-8 encoded character would use between 1 and 3 bytes. The beauty of UTF-8 is that it is compatible with ASCII (and by proxy the beginning of ISO-8859-1, which is also ASCII compatible) for the most common characters in English, using only 1 byte, but that the variable-width encoding scheme lets it also support the rest of Unicode. Here's the rub: \"the rest of Unicode\" is an expanding set and when it passed a certain boundary UTF-8 needed 4 bytes to handle it. Let's have an example:\n\n<code>\n1 byte \u00a0(0000-007F):\u00a0\"A\" \u00a0\u2794 0x41\n2 bytes (0080-07FF): \"\u0416\" \u2794 0xD0 0x96\n3 bytes (0800-FFFF): \"\u9f8d\" \u2794 0xE9 0xBE 0x8D\n4 bytes (&gt; FFFF) \u00a0 : \"\ud801\udc12\" \u2794 0xF0 0x90 0x90 0x92</code>\n\nAs you can see above, that last character takes 4 bytes in UTF-8 while MySQL only expects 1-3 bytes per character.\u00a0Without getting into too many Unicode details it's important for our discussion to know that the Unicode characters are logically divided into \"<a href=\"http://en.wikipedia.org/wiki/Unicode_plane\">planes</a>\". The first plane is the Basic Multilingual Plane (BMP) and what you probably think of as \"Unicode\". This is all of the characters between <code>U+0000</code> and <code>U+FFFF</code> and covers most of the characters for the major languages of the world. When Unicode starting using the additional planes it started addressing characters beyond <code>U+FFFF</code> and UTF-8 expanded to handle that.\n\nThe MySQL 5.1 <code>CHARSET</code> \"<code>utf8</code>\" and the <code>utf8_*</code> collations were only able to handle 1-3 bytes so they had to do something. That something was mentioned depends on your client driver. In Ruby the insert succeeds but the data is discarded. In Java an exception is thrown, which at least alerts you to the problem.\u00a0With the addition of <a href=\"http://en.wikipedia.org/wiki/Emoji\">Emoji</a> in Unicode 6.0 this problem has a very high profile failure case when the text is Emoji-only. For Japanese mobile phone users this not an uncommon use case, and you can expect it to get more common in the US very soon.\n<h3>The problem with accents</h3>\nThe problem I mentioned above with accent changes not taking effect is actually a configuration problem rather than a MySQL bug. This has to do with the common misunderstandings around MySQL collation and specifically the <code>utf_general_ci</code>/<code>utf_uncode_ci</code> collation sequences. This is probably best illustrated with an example:\n\n<code>\nmysql&gt; select \"bar\" = \"b\u00e4r\" COLLATE utf8_unicode_ci\\G\n*************************** 1. row ***************************\n\"bar\" = \"b\u00e4r\" COLLATE <strong>utf8_unicode_ci: 1</strong>\nmysql&gt; select \"bar\" = \"b\u00e4r\" COLLATE utf8_general_ci\\G\n*************************** 1. row ***************************\n\"bar\" = \"b\u00e4r\" COLLATE <strong>utf8_general_ci: 1</strong>\nmysql&gt; select \"bar\" = \"b\u00e4r\" COLLATE utf8_bin\\G\n*************************** 1. row ***************************\n\"bar\" = \"b\u00e4r\" COLLATE <strong>utf8_bin: 0</strong>\n</code>\n\nIf your default collation is <code>utf_general_ci</code> or <code>utf_uncode_ci</code> then your database thinks \"bar\" and \"b\u00e4r\" are the same word. If you have unique constraints on a column this is clearly problematic but this can also cause problems without that. This is the root cause of the \"accent changes won't save\" problem. When updating a record it appears MySQL (or at least InnoDB) checks for equality before updating a record. Since and accent-only change is considered equal by the collation MySQL skips the write (which saves I/O overhead) and returns success since it thinks it optimized a write rather than failing.\n\nEnglish speaking developers very often assume that MySQL is mature and will \"just work\" in every language. The default character set for MySQL is <code>latin1</code> (rather than <code>utf8</code>) and many developers have learned to dutifully change that to <code>utf8</code> and <code>utf8_general_ci</code> when they install MySQL. This change fixes a large swath of issues but leaves behind these much more subtle bugs.\n<h2>The MySQL 5.1 guidelines and work arounds</h2>\nIf you need to stay on MySQL 5.1 there are a few things worth keeping in mind.\n<ul>\n\t<li>Using <code>utf8_bin</code> for collation will solve the accent issues, which is probably what you thought the other <code>utf8_*</code> collations where doing. The downside to this is that <code>utf8_bin</code> and <code>ORDER BY</code> will not be in language-specific order. You'll have to make the choice for yourself depending on your needs but my advice would be that if you don't know you should go with <code>utf8_bin</code>.</li>\n\t<li>If you want to fully support non-BMP characters your only recourse is to convert your <code>char</code>/<code>varchar</code> column in question to a <code>binary</code>/<code>varbinary</code> and make sure you handle the character encoding correctly on the way in and out. If you use UTF-8 be sure to allow 4 bytes per character (as discussed above). If you use UTF-16, make sure you allow 4-bytes to handle <a href=\"http://en.wikipedia.org/wiki/Mapping_of_Unicode_characters#Surrogates\">surrogate pairs</a>. The downside to this is the subtle differences in how <a href=\"http://dev.mysql.com/doc/refman/5.1/en/binary-varbinary.html\">binary and varbinary columns</a> are stored and you should fully understand that and the performance implications before making any changes.</li>\n</ul>\n<h2>The MySQL 5.5 fix</h2>\nMySQL 5.5 was just released with new character sets for <code>utf8mb4</code>, <code>utf16</code> and <code>utf32</code>. While <code>utf16</code> and <code>utf32</code> support is certainly welcomed I want to focus on <code>utf8mb4</code> since my assumption is that you want ASCII compatibility. The newly added\u00a0<a href=\"http://dev.mysql.com/doc/refman/5.5/en/charset-unicode-utf8mb4.html\"><code>utf8mb4</code></a> character set is a superset of the <code>utf8</code> character set that can store up to 4 bytes per character. With 4 bytes per character <code>utf8mb4</code> should be able to store all 16 planes, including planes 4-13 which are currently empty and given the known writing systems in the world are not expected to be filled.\n\nThe addition of <code>utf8mb4</code> makes me breath a little easier. You still have to know your collations to not reproduce the accent problem but I trust you can remember that small piece of Unicode/MySQL knowledge. If not, maybe you'll google again in the future an find this handy command:\n<blockquote><code>ALTER TABLE table_name CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_bin;</code></blockquote>", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "133", 
            "link": "http://mzsanford.wordpress.com/2010/12/28/mysql-and-unicode/", 
            "name": "mysql-and-unicode", 
            "post_date": "2010/12/28 21:51:08Z", 
            "status": "publish", 
            "tags": [], 
            "title": "MySQL and Unicode"
        }, 
        {
            "categories": [
                "Culture", 
                "Twitter"
            ], 
            "comments": [
                {
                    "author": "Tweets that mention The Effort of Content Creation: An Evolution \u00ab Matt Sanford -- Topsy.com", 
                    "author_email": "", 
                    "author_ip": "208.74.66.43", 
                    "author_url": "http://topsy.com/mzsanford.wordpress.com/2011/02/19/content-creation-evolution/?utm_source=pingback&utm_campaign=L2", 
                    "content": "[...] This post was mentioned on Twitter by Matt Sanford, Zach Hanna. Zach Hanna said: RT @mzsanford: From Geocities to Blogger to Twitter, an evolution (new blog post): http://bit.ly/content-evolution [...] ", 
                    "post_date": "2011/02/20 01:29:34Z"
                }
            ], 
            "content": "Much like my previous posts about <a title=\"The Honest\u00a0Omnivore\" href=\"http://mzsanford.wordpress.com/2010/05/16/the-honest-omnivore/\" target=\"_blank\">omnivores</a> and <a title=\"MC Hammer showed me the future of\u00a0Twitter\" href=\"http://mzsanford.wordpress.com/2010/12/22/mc-hammer-showed-me-the-future-of-twitter/\" target=\"_blank\">MC Hammer</a> this is something I've told many people in person but I'm only just now putting down in writing. Many people ask me why I think Twitter is popular, thinking there is some part of it they have yet to see. The 'killer feature' isn't some page on twitter.com they haven't seen yet but rather it's the simplicity of what they already see. It's not about something complicated but rather the sum of the uncomplicated parts \u2026 not unlike the internet itself. I'm way ahead of myself. This post is about the evolution of people's self-expression on the internet, people's internet-identity, and how I see Twitter in that context. This isn't some lofty vision from a Twitter founder or executive. This is the view from a guy who just happened upon all of this and is still trying to explain it however he can \u2013 to himself most of all.\n<h1>In the beginning, there was Geocities</h1>\nWhen I first heard of mainstream internet usage there was a general feeling of excitement about every person being able to share their views and knowledge with anyone interested. Internet savvy people practically stood on soap boxes in town squares telling people they should\u00a0 have a presence on the internet. After all, the greatness of the internet is the fact that any one of us can have a site all our own \u2013 our own internet-identity. Enter Geocities, a free way to host a site of your own (I know there were others, but Geocities captured the imagination) for the modest price of learning HTML. Or, as luck would have it, there were some templates to get you started.\n\nSome people were drawn to the internet by this and stayed. Most, however, put together a hasty page with a few words and an <a title=\"Iconic of Geocities\" href=\"http://www.cs.utah.edu/~gk/atwork/\" target=\"_blank\">\"Under Construction\" icon</a> and moved on to other things. Even those who spent the time learning HTML, or finding a good template, soon felt like they just didn't have enough to say to fill a site. Posting was technically difficult, graphic design was harder than anticipated but what killed the Geocities utopia more than anything was that most people realized they just didn't have enough to say to make it <em>worth</em> all of that effort. If this self-expression on the internet thing was going to work out something had to give.\n<h1>And then came Blogger</h1>\nThe homepage craze died down among the majority but it was clear that the internet-identity and self-expression dream still lived on. While I don't know if that was the direct inspiration for blogs I would argue it led directly to it. It was clear to the creators of early blog platforms (Blogger as an early and popular example) that people had things to say and there was a business in making that easier. Blog platforms removed most, if not all, of the technical and design challenges that the home page era had suffered from. All you needed to blog was an idea and the time to write about it.\n\nBlog platforms made (and still make) publishing easy but they didn't do anything to ease what I see as the crux of the problem. You see, most blogs stop after a <a title=\"Original\" href=\"http://www.caslon.com.au/weblogprofile1.htm\" target=\"_blank\">month or two</a> (<a title=\"Google Cache FTW!\" href=\"http://webcache.googleusercontent.com/search?q=cache:HnMsQWnK0ZEJ:www.caslon.com.au/weblogprofile1.htm\" target=\"_blank\">cached</a>) and the main reasons are a lack of things to say and the time it takes to create a long-form blog post. That lack of things to say might be true or it might just be in the eyes of the author. Hell, my own update rate is erratic for just that reason. If I have a spare few hours I don't run to post what's on my mind for nobody to read. I only write when I feel I have both the time and the personal desire to get something off my chest - reader be damned (sorry).\n<h1>And here we are at Twitter</h1>\nI talked about Twitter in the intro and here is where it all ties back. I see Twitter as the next logical step in the process and that's part of how I use it. There is no longer a technical or design learning curve and the amount of effort required at any one time is small. Twitter does not replace all blogs, just like blogs did not replace all home pages. This has all been an evolution from having a whole site that was infused with you in both design and content; to a place that expressed your views in traditional long-form content; and now to the sum of your small thoughts and observations. It turns out those small bits add up to your self-expression and your identity on the internet. You are what you say , what you do, and even what you repeat, on the internet just like everywhere else.\n\nCould it get simpler to publish? Sure. Could you distill human communication down any more? Perhaps. Maybe that's the vision for <a title=\"Whois?\" href=\"http://whois.domaintools.com/gruntr.com\" target=\"_blank\">gruntr.com</a> \u2026 maybe the next big thing will be a system where you can only poke and grunt. Physical-gesture-over-IP? I'm in. Watch out AT&amp;T Wireless customer service, I foresee some angry gestures from SF residents.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "142", 
            "link": "http://mzsanford.wordpress.com/2011/02/19/content-creation-evolution/", 
            "name": "content-creation-evolution", 
            "post_date": "2011/02/19 22:56:40Z", 
            "status": "publish", 
            "tags": [], 
            "title": "The Effort of Content Creation: An Evolution"
        }, 
        {
            "categories": [
                "Twitter", 
                "Programming"
            ], 
            "comments": [], 
            "content": "This is post is about how I have come to use the words \"crowdsourced\" and \"community\" to distinguish different, but related, activities. I've been working on Twitter's community translation tools since before they were launched and this is a lesson I've learned during that time. This all started with my reply to a <a href=\"http://www.quora.com/What-key-benefits-did-Twitter-and-Facebook-uncover-in-crowdsourcing-their-translations\">Quora topic</a> \u00a0and much of the information was already covered there. But since Quora is a smaller community than the web at large I wanted to re-format the information for widest consumption and change some of the examples to be a little bit clearer.\n\n<!--more-->As I mentioned above I've been working on Twitter's community translation tools from the beginning. I originally called it \"crowdsourced translation\" but over time I've come to call it \"community translation\" and appreciate the subtle difference between the two terms, or at least started using them to mean two slightly different, but similar, things. The explanation of that difference explains is a little interesting but it's most interesting because it highlights the biggest benefits Twitter has seen from translating this way.\n\nI see \"crowdsourcing\" as an activity that requires very<strong>\u00a0little or no prior knowledge</strong>\u00a0of the problem space at hand and which can benefit solely from a wealth of different opinions/views/activities. A great example of this is search engine relevance evaluations. At their most basic these evaluations ask a group of people to search for a term and mark different links on the results as on- or off-topic. In more complicated scenarios they ask the participants to re-order the links into the \"best\" order, or to compare two result pages side-by-side and pick which is best. In all of these scenarios the activity does not require that the person have any idea how search engines work. You're not asking an expert in the field to\u00a0evaluate\u00a0something, you're asking the largest, most diverse group possible to evaluate it so you can understand the problem.\n\nIn the case of Twitter's Translation Center we rely heavily on our user's\u00a0<strong>prior knowledge</strong>\u00a0of Twitter itself. While that might seem like a minor difference it matches exactly what\u00a0Nicholas Muldoon\u00a0said above about Atlassian in the <a href=\"http://www.quora.com/What-key-benefits-did-Twitter-and-Facebook-uncover-in-crowdsourcing-their-translations\">original Quora topic</a>, \"<em>translations provided by our Language Service Provider were not translated by people who used the product</em>\". Twitter has also experimented with Language Service Providers (LSPs) and they do a great job at some types of tasks, while at others they don't. The reason I now call it \"community translation\" is that we have taken an existing community of users\u00a0and asked them to help based on prior knowledge. We did not take a group of people at random, but an existing community (bi-lingual Twitter users). We also didn't take a collection of professional translators because while our task is translation our actual problem space is actually Twitter, and how it uses language.\n\nOne quick example to highlight the difference in community translation quality versus professional translators: Twitter uses the word \"<em>unfollow</em>\" to label the button that stops following another account. If you ask an LSP to translate this they will likely return a phrase such as \"<em>Nicht mehr folgen</em>\" in German. If you ask a translator (or linguist) directly they will probably point out that \"<em>unfollow</em>\" isn't a word. Twitter's language is very informal in English and community translation has helped us keep that playful tone in every language (even the ungrammatical \"<em>Entfolgen</em>\" in German). This might seem like a small thing but the\u00a0consistency\u00a0of product language with the product itself is really the key to translation quality. The localization industry has known this for ages and has made great strides in \"source document quality\" to that end (limited grammars, style guides, etc.).\n\nAs\u00a0Alex Lane\u00a0said in the original Quora topic nobody is crowdsourcing advertising, accounting or legal translation work (he might have meant the functions and not translations, but I took it to mean translation). Even Twitter does not do that because the language of those domains is formal. Our community of translators are an asset because they know our domain so well. They don't know those more formal domains so they would do as poorly at those as an LSP does with things like \"<em>unfollow</em>\".", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "164", 
            "link": "http://mzsanford.wordpress.com/2011/06/15/crowdsourcing-vs-community/", 
            "name": "crowdsourcing-vs-community", 
            "post_date": "2011/06/15 16:54:55Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Crowdsourcing vs. Community"
        }, 
        {
            "categories": [
                "Languages", 
                "Programming"
            ], 
            "comments": [], 
            "content": "I'm proud to announce the release of what is possibly the smallest Ruby gem I've ever worked on, <a href=\"https://github.com/mzsanford/r2rb\">R2</a>\u00a0(<a title=\"R2rb on github\" href=\"https://github.com/mzsanford/r2rb\">R2rb</a> on github, simply <a title=\"r2 on Rubygems.org\" href=\"http://rubygems.org/gems/r2\">r2</a> on rubygems.org).\u00a0Anybody who has read my older posts knows that I'm interested in Arabic, and more specifically Arabic information processing. While talking about something unrelated I found out that Dustin Diaz (<a href=\"http://twitter.com/ded\">@ded</a>,\u00a0<a href=\"http://dustindiaz.com\">dustindiaz.com</a>)\u00a0has written a Node.js module called <a href=\"https://github.com/ded/r2\">R2</a> for mirroring the appropriate CSS values needed to alter the directionality of a page. While this isn't a silver bullet it does do a very good job on pages that have successfully\u00a0separated\u00a0presentation from markup (read as: don't use inline CSS styles).\n\nThe code itself is shockingly simple but effective. Dustin already has an example built into his website. Here is the normal page (emphasis added to the demo link):\n<p style=\"text-align:center;\"><a href=\"http://mzsanford.files.wordpress.com/2011/06/ltr.jpg\"><img class=\"aligncenter size-full wp-image-176\" style=\"margin-top:10px;margin-bottom:10px;border-color:black;border-style:solid;border-width:1px;\" title=\"Normal left-to-right view\" src=\"http://mzsanford.files.wordpress.com/2011/06/ltr.jpg\" alt=\"dustindiaz.com as seen by default\" width=\"630\" height=\"371\" /></a></p>\nWhen you click the demo link (pointed to with the <span style=\"color:#800000;\"><strong>Click Me.</strong></span> label) there is a small amount of Javascript that alters the link tag to point the the CSS file that R2 has processed. The resulting page shows the CSS direction change with zero customization:\n<p style=\"text-align:center;\"><a href=\"http://mzsanford.files.wordpress.com/2011/06/rtl.jpg\"><img class=\"aligncenter size-full wp-image-177\" style=\"margin-top:10px;margin-bottom:10px;border-color:black;border-style:solid;border-width:1px;\" title=\"Altered right-to-left site\" src=\"http://mzsanford.files.wordpress.com/2011/06/rtl.jpg\" alt=\"dustindiaz.com as seen after clicking the arrow\" width=\"630\" height=\"320\" /></a></p>\nWhile this is obviously not everything one needs to do for right-to-left support (of note above are the Twitter follow buttons) it's a good starting point. If you have a large CSS file to start with the alterations can be daunting. I recommend using R2 and then troubleshooting the remaining bugs. I created a Ruby port of R2 in part to improve my understanding of R2 and in part in the hopes of using it in some future Rails project.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "173", 
            "link": "http://mzsanford.wordpress.com/2011/06/17/r2rb-mirroring-css-direction/", 
            "name": "r2rb-mirroring-css-direction", 
            "post_date": "2011/06/18 00:38:41Z", 
            "status": "publish", 
            "tags": [], 
            "title": "R2rb - Mirroring CSS direction"
        }, 
        {
            "categories": [
                "Twitter", 
                "Programming"
            ], 
            "comments": [], 
            "content": "Browser incompatibility is so 1999, isn't it? Well, while we spend our time fretting about IE version incompatibility and cross-browser issues we often overlook the version issues of other browsers. Over the past week I've been working on the <a href=\"https://github.com/twitter/twitter-text-js\">twitter-text-js</a> support for hashtags in Russian, Korean, Japanese and Chinese. Along the way I ran into two bugs in some versions of Safari that surprised me. I didn't find much online about it so I wanted to take a moment and jot this down.\n<h2>Non-ASCII URL Hashes</h2>\nThe first bug I ran into has to do with assigning a new value to <code>window.location.hash</code> in Javascript. Our site uses the hash (or anchor) portion of the URL quite extensively in something generally called \"hashbang URLs\". Two of my\u00a0colleagues\u00a0at Twitter have discussed the <a href=\"http://www.adequatelygood.com/2011/2/Thoughts-on-the-Hashbang\">pros</a> and <a href=\"http://danwebb.net/2011/5/28/it-is-about-the-hashbangs\">cons</a> of this approach publicly but what's important here is that we use it today and therefore do more work with the hash portion of the URL than most people. This matters for hashtags because we catch the click on hashtag links and navigate by assigning the search to the <code>window.location.hash</code>.\n\nSafari 5.0.5, and possibly earlier versions, are buggy in the implementation of assignment to <code>window.location.hash</code>. This isn't a quirk, or a feature-I-do-not-appreciate, this is a bug. It's fixed in 5.1 which makes me very happy. Our site was attempting to assign\u00a0<code>#\u0442\u043e\u043c\u0441\u043a</code> to the window.location.hash but the page kept switching to\u00a0<code>#B&gt;&lt;A:</code>. After a bit of reflection on the issue I noticed that the two are the exact same number of characters. What a curious coincidence. Well, it turns out it's much worse than I thought:\n\n[caption id=\"attachment_185\" align=\"aligncenter\" width=\"580\" caption=\"Safari 5.0.5 hash alteration\"]<a href=\"http://mzsanford.files.wordpress.com/2011/07/untitled-1.jpg\"><img class=\"size-full wp-image-185\" title=\"What happened to by high order bits?\" src=\"http://mzsanford.files.wordpress.com/2011/07/untitled-1.jpg\" alt=\"\" width=\"580\" height=\"340\" /></a>[/caption]\n\nLook at that! Safari 5.0.5 seems to have turned all of our well formed Unicode into ASCII by stripping out all of the high bits. I thought this must be a problem with our page but our pages are UTF-8 encoded so those are not even the bytes on our page (and it also works in all other browsers, which is always suspicious). The fix for this was quite simple. If you re-build the complete URL and assign it to <code>window.location.href</code> the encoding is left intact. As a bonus, Safari correctly\u00a0recognizes\u00a0that the only change was the hash and does not trigger a full page reload. If you're using hashbang URLs in languages other than English this might bite you. Beware of changing to <code>window.location.href</code> because IE does a full page reload, thus disabling your carefully crafted hasbang plans.\n<h2>Regular Expression Size Limit</h2>\nAfter testing our new hashtag regular expression in a myriad of browsers we thought we were covered. It turns out that Safari 4.0 and below have a limit on the maximum size of a regular expression that is lower than the browsers we tested. I had tested in Safari 5.1, because it is what I have, as well as several versions of Firefox and IE. Running multiple versions of Safari on a Mac is somewhere between impossible and difficult as far as I can tell, so beware of this one because it's hard to test.\n\nThe regular expression in question contained a character class that had every Chinese character, which was admittedly excessive. We were able to refactor into character ranges and verify that it works in all of our supported browsers, so this was more of a coding\u00a0inconvenience\u00a0that a serious bug. The inability to run two versions of Safari feels like it's setting me up for more failures like this in the future. If versions don't act the same (and they shouldn't, otherwise what's the point?) then developers will need a way to run multiple versions to test. Without that this is a losing battle.", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "175", 
            "link": "http://mzsanford.wordpress.com/2011/07/14/sufferin-safari-version-quirks/", 
            "name": "sufferin-safari-version-quirks", 
            "post_date": "2011/07/14 19:06:24Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Sufferin' Safari: Quirks Between Safari Versions"
        }, 
        {
            "categories": [
                "Automotive"
            ], 
            "comments": [], 
            "content": "After a minor accident I needed to replace the rear fender on my 2001 Vespa ET4. The person who rear-ended me was curious what was\u00a0entailed\u00a0in replacing the part but we couldn't find a good time for him to visit while I made the repairs. I busted out my handy iPhone and took pictures of my repair progress so I could share. This post is really aimed at that one person but should anyone need to replace the fender on an ET series (especially one with crash bars) hopefully this helps.\n\n<!--more-->\n<h2>1. Before the replacement</h2>\n[caption id=\"attachment_198\" align=\"aligncenter\" width=\"224\" caption=\"Image 1.1: Before view of the fender\"]<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1516.jpg\"><img class=\"size-medium wp-image-198  \" title=\"Before: Broken fender\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1516.jpg?w=224\" alt=\"Mah fender is busted.\" width=\"224\" height=\"300\" /></a>[/caption]\n\nBeing rear-ended on a scooter, even at low speed, is pretty jarring. We were stopped and he just rolled into me but it felt like when a clutch slips on an manual scooter and you jump forward. There\u00a0weren't\u00a0any injuries and as you can see above it only cracked one part. What you can't see above is the seam behind the chrome crash bar. The back fender is made of plastic and holds the license plate, license plate light and a reflector.\n<h2>2. Removing the crash bars</h2>\nThe crash bars have saved the body of my scooter more than once. Taking these things off is a pain in the butt because they hug the body very closely. Taking off the front part of the bars requires a socket (13mm) as well as something to hold the nut on the back (pliers in this case). I loosened these on both sides but didn't remove them immediately because I needed the bars to stay in position for the nest step. I couldn't take a picture with both the wrench and the pliers on at the same time since one hand needed to hold the camera. However, this should give you the idea:\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1517.jpg\"><img class=\"size-medium wp-image-199 alignnone\" title=\"Front of the crash bar (socket)\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1517.jpg?w=224\" alt=\"Front of the crash bar (outside wrench)\" width=\"224\" height=\"300\" /></a>\u00a0 \u00a0\u00a0<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1520.jpg\"><img class=\"size-medium wp-image-200 alignnone\" title=\"Front of the crash bar (inside pliers)\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1520.jpg?w=224\" alt=\"Front of the crash bar (inside pliers)\" width=\"224\" height=\"300\" /></a>\n\nWith the front bolts loose I was able to move to the rear bolts. Once again I needed to use a wrench on the outside (11mm) and pliers on the inside (plier picture omitted, you get the idea):\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1521.jpg\"><img class=\"size-medium wp-image-201 alignnone\" title=\"Back of the bar (socket)\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1521.jpg?w=224\" alt=\"Back of the bar (outside wrench)\" width=\"224\" height=\"300\" /></a>\n\nThe crash bars are supported in the back by a bracket that passes over the tire and rests on the inside of the fender (image one). That bracket is held on at the sides by the rear bolts mentioned above so once they are removed you can slide the bracket out and then remove the loosened front bolts and remove the bars completely (image two):\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1523.jpg\"><img class=\"alignnone size-medium wp-image-202\" title=\"Back bracket, held in place\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1523.jpg?w=224\" alt=\"Back bracket, held in place\" width=\"224\" height=\"300\" /></a>\u00a0\u00a0<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1524.jpg\"><img class=\"alignnone size-medium wp-image-203\" title=\"Full bars\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1524.jpg?w=224\" alt=\"Full bars off the bike\" width=\"224\" height=\"300\" /></a>\n<h2>3. Remove the fender</h2>\nRemoving the fender itself after the crash bars in quite simple. I have photographed the steps on the left side of the scooter below but the right side is just a mirror image. I started by removing the license plate light, which is held in place by a rubber grommet and nothing more. It's a bit hard to see in the two images below but these are pictures taken from the ground, under the inside of the fender. The circle of light in image two is the sun coming in the license plate light hole. If you compare the two photos you should be able to see the rubber grommet around the base of the bulb. That's all that held it in so a light tug dislodged it:\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1531.jpg\"><img class=\"alignnone size-medium wp-image-208\" title=\"Inside (light in place)\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1531.jpg?w=300\" alt=\"Inside fender (light in place)\" width=\"300\" height=\"224\" /></a>\u00a0\u00a0<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1532.jpg\"><img class=\"alignnone size-medium wp-image-209\" title=\"Inside (light pulled)\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1532.jpg?w=300\" alt=\"Inside fender (light pulled)\" width=\"300\" height=\"224\" /></a>\n\nNow on to the real body panels. If you pull up the back corner of the floor mat you'll see a large screw which needs to be removed:\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1526.jpg\"><img class=\"alignnone size-medium wp-image-204\" title=\"Lift the floor mat\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1526.jpg?w=224\" alt=\"Lift the floor mat\" width=\"224\" height=\"300\" /></a>\u00a0\u00a0<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1527.jpg\"><img class=\"alignnone size-medium wp-image-205\" title=\"Bolt under the floor mat\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1527.jpg?w=224\" alt=\"Bolt under the floor mat\" width=\"224\" height=\"300\" /></a>\n\nOnce the screw is removed the lower panel of the cowl can be pulled off. Start by pulling on the side closest to the front of the scooter because the back edge is hooked into the fender (see image one). Once the lower panel is removed you have a clear view of the fender mounting screw (image two):\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1529.jpg\"><img class=\"alignnone size-medium wp-image-206\" title=\"Pull off the lower panel\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1529.jpg?w=224\" alt=\"Pull off the lower panel\" width=\"224\" height=\"300\" /></a>\u00a0\u00a0<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1530.jpg\"><img class=\"alignnone size-medium wp-image-207\" title=\"Fender mounting screw\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1530.jpg?w=224\" alt=\"Fender mounting screw\" width=\"224\" height=\"300\" /></a>\n\nWhen the mounting screws have been remove from both sides the fender just needs a light tug to come off. You can see below the old \u00a0 part with all of the accessories on it next to the new part:\n\n[caption id=\"attachment_210\" align=\"aligncenter\" width=\"300\" caption=\"New and old, side by side\"]<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1533.jpg\"><img class=\"size-medium wp-image-210\" title=\"Side by side\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1533.jpg?w=300\" alt=\"Side by side\" width=\"300\" height=\"224\" /></a>[/caption]\n<h2>4. Transfer the accessories</h2>\nThe license plate it held on by four slot-headed screws that require pliers to hold the square nuts on the far side. Once the plate is remove you can clearly see the license plate bracket (image one, shown upside down, sorry.), which is held on by three screws that have nuts (7mm) on the back side. The license plate light housing (which is fronted by a reflector) is held on by two screws from the inside (image two, also upside down, sorry):\n\n<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1534.jpg\"><img class=\"alignnone size-medium wp-image-211\" title=\"License plate bracket\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1534.jpg?w=224\" alt=\"License plate bracket\" width=\"224\" height=\"300\" /></a>\u00a0\u00a0<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1535.jpg\"><img class=\"alignnone size-medium wp-image-212\" title=\"Screws for the light housing\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1535.jpg?w=224\" alt=\"Screws for the license plate light housing\" width=\"224\" height=\"300\" /></a>\n\nAnd once all of that is removed you have a mess on the sidewalk and someone with a dog is bound to come upon you and give you the stink eye. Remind yourself that they have likely helped add to the feces content of SF streets and feel smug that your shit will be cleaned up in the next 15 minutes and won't leave a smear that some poor fool steps in. My mess looked something like this, but your mess may vary:\n\n[caption id=\"attachment_213\" align=\"aligncenter\" width=\"224\" caption=\"A mess.\"]<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1536.jpg\"><img class=\"size-medium wp-image-213\" title=\"Everything asunder \" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1536.jpg?w=224\" alt=\"Everything asunder\" width=\"224\" height=\"300\" /></a>[/caption]\n<h2>5. Conclusion</h2>\nThe steps were easy to repeat in reverse so I don't see any use in detailing that here. The finished product looks good, though the paint is not a perfect match due to aging:\n\n[caption id=\"attachment_214\" align=\"aligncenter\" width=\"224\" caption=\"Ta-da!\"]<a href=\"http://mzsanford.files.wordpress.com/2011/11/img_1537.jpg\"><img class=\"size-medium wp-image-214\" title=\"Done.\" src=\"http://mzsanford.files.wordpress.com/2011/11/img_1537.jpg?w=224\" alt=\"Completed product\" width=\"224\" height=\"300\" /></a>[/caption]\n\nThis is an off-topic blog post about a scooter\u00a0repair meant for one (or maybe two) people to read. If you're not one of those people and you're reading this then hopefully you found this through some very obscure search and you're saying \"Thank god somebody wrote this down\". I leave you with this moment of zen:\n<p style=\"text-align:center;\"><a href=\"http://xkcd.com/979/\"><img class=\"aligncenter\" title=\"Thanks god someone wrote this down\" src=\"http://imgs.xkcd.com/comics/wisdom_of_the_ancients.png\" alt=\"\" width=\"485\" height=\"270\" /></a></p>", 
            "creator": "mzsanford", 
            "description": "", 
            "id": "183", 
            "link": "http://mzsanford.wordpress.com/2011/11/20/vespa-et4-fender-replacement/", 
            "name": "vespa-et4-fender-replacement", 
            "post_date": "2011/11/21 00:19:05Z", 
            "status": "publish", 
            "tags": [], 
            "title": "Vespa Fender Replacement"
        }
    ], 
    "tags": [], 
    "title": "Matt Sanford"
}